{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "952e5fcd",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-09T05:28:58.701601Z",
     "iopub.status.busy": "2025-03-09T05:28:58.701379Z",
     "iopub.status.idle": "2025-03-09T05:28:59.393909Z",
     "shell.execute_reply": "2025-03-09T05:28:59.393086Z"
    },
    "papermill": {
     "duration": 0.697797,
     "end_time": "2025-03-09T05:28:59.395170",
     "exception": false,
     "start_time": "2025-03-09T05:28:58.697373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar_test_nolabel.pkl\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/data_batch_1\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/data_batch_2\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/batches.meta\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/test_batch\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/data_batch_3\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/data_batch_5\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/data_batch_4\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/readme.html\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10bae22d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T05:28:59.401286Z",
     "iopub.status.busy": "2025-03-09T05:28:59.400974Z",
     "iopub.status.idle": "2025-03-09T05:29:09.022325Z",
     "shell.execute_reply": "2025-03-09T05:29:09.021395Z"
    },
    "papermill": {
     "duration": 9.625669,
     "end_time": "2025-03-09T05:29:09.023631",
     "exception": false,
     "start_time": "2025-03-09T05:28:59.397962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'airplane', b'automobile', b'bird', b'cat', b'deer', b'dog', b'frog', b'horse', b'ship', b'truck']\n",
      "50000\n",
      "50000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "classes_dict = unpickle(\"/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/batches.meta\")\n",
    "label_names = classes_dict[b'label_names']\n",
    "print(label_names)\n",
    "\n",
    "# Load training data in batches, then combine\n",
    "training_data = []\n",
    "training_labels = []\n",
    "for i in range(1, 6):\n",
    "    training_fp = \"/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/data_batch_{}\".format(i)\n",
    "    batch = unpickle(training_fp)\n",
    "    batch_data = batch[b'data']\n",
    "    batch_labels = batch[b'labels']\n",
    "    for i in range(len(batch_data)):\n",
    "        training_data.append(batch_data[i])\n",
    "        training_labels.append(batch_labels[i])\n",
    "\n",
    "# Load test dataset\n",
    "testing_fp = '/kaggle/input/deep-learning-spring-2025-project-1/cifar_test_nolabel.pkl'\n",
    "testing_batch = unpickle(testing_fp)\n",
    "testing_data = testing_batch[b'data']\n",
    "\n",
    "print(len(training_data))\n",
    "print(len(training_labels))\n",
    "print(len(testing_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e023b51e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T05:29:09.030267Z",
     "iopub.status.busy": "2025-03-09T05:29:09.029927Z",
     "iopub.status.idle": "2025-03-09T05:29:09.034528Z",
     "shell.execute_reply": "2025-03-09T05:29:09.033882Z"
    },
    "papermill": {
     "duration": 0.009044,
     "end_time": "2025-03-09T05:29:09.035626",
     "exception": false,
     "start_time": "2025-03-09T05:29:09.026582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_to_rgb_tensor(image):\n",
    "    rgb_image = np.zeros((32, 32, 3), dtype=np.uint8)\n",
    "    red_idx, green_idx, blue_idx = 0, 1024, 2048\n",
    "    for row in range(0, 32):\n",
    "        for col in range(0, 32):\n",
    "            rgb_image[row, col] = [image[red_idx], image[green_idx], image[blue_idx]]\n",
    "            red_idx += 1\n",
    "            green_idx += 1\n",
    "            blue_idx += 1\n",
    "\n",
    "    rgb_tensor = transforms.ToTensor()(rgb_image)\n",
    "    return rgb_tensor\n",
    "\n",
    "# Test on Random Image\n",
    "# rand_num = random.randint(0, 10000)\n",
    "# rand_image = data_batch_1[b'data'][rand_num]\n",
    "# rand_image_rgb = convert_to_rgb(rand_image)\n",
    "\n",
    "# rand_img_data = Image.fromarray(rand_image_rgb, 'RGB')\n",
    "# img_data.save('test.png')\n",
    "# label = data_batch_1[b'labels'][rand_num]\n",
    "# print('Expected Image: ', label, '-', label_names[label])\n",
    "\n",
    "# ADD VISUAL DISPLAY OF IMAGE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dff37bc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T05:29:09.041318Z",
     "iopub.status.busy": "2025-03-09T05:29:09.041096Z",
     "iopub.status.idle": "2025-03-09T05:29:59.685489Z",
     "shell.execute_reply": "2025-03-09T05:29:59.684839Z"
    },
    "papermill": {
     "duration": 50.648931,
     "end_time": "2025-03-09T05:29:59.687110",
     "exception": false,
     "start_time": "2025-03-09T05:29:09.038179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_data = [convert_to_rgb_tensor(image) for image in training_data]\n",
    "# training_data = np.array(training_data)\n",
    "# training_labels = np.array(training_labels)\n",
    "training_data = [(image, label) for image, label in zip(training_data, training_labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "855dafa1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T05:29:59.693570Z",
     "iopub.status.busy": "2025-03-09T05:29:59.693327Z",
     "iopub.status.idle": "2025-03-09T05:29:59.708024Z",
     "shell.execute_reply": "2025-03-09T05:29:59.707411Z"
    },
    "papermill": {
     "duration": 0.019151,
     "end_time": "2025-03-09T05:29:59.709280",
     "exception": false,
     "start_time": "2025-03-09T05:29:59.690129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_count = int(0.8 * len(training_data))\n",
    "validation_count = int(0.2 * len(training_data))\n",
    "\n",
    "training_data, validation_data = random_split(training_data, [training_count, validation_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "805b0e93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T05:29:59.715169Z",
     "iopub.status.busy": "2025-03-09T05:29:59.714950Z",
     "iopub.status.idle": "2025-03-09T05:29:59.729890Z",
     "shell.execute_reply": "2025-03-09T05:29:59.729090Z"
    },
    "papermill": {
     "duration": 0.019326,
     "end_time": "2025-03-09T05:29:59.731206",
     "exception": false,
     "start_time": "2025-03-09T05:29:59.711880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "#Basic Residual Block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        #when in_channels != out_channels\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)  #residual connection\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        return out\n",
    "\n",
    "class SimpleResNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = ResidualBlock(64, 64, stride=2)\n",
    "        self.layer2 = ResidualBlock(64, 128, stride=2)\n",
    "        self.layer3 = ResidualBlock(128, 256, stride=2)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = self.dropout(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48de7109",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T05:29:59.737018Z",
     "iopub.status.busy": "2025-03-09T05:29:59.736824Z",
     "iopub.status.idle": "2025-03-09T05:30:00.694712Z",
     "shell.execute_reply": "2025-03-09T05:30:00.693624Z"
    },
    "papermill": {
     "duration": 0.96235,
     "end_time": "2025-03-09T05:30:00.696201",
     "exception": false,
     "start_time": "2025-03-09T05:29:59.733851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "              ReLU-3           [-1, 64, 32, 32]               0\n",
      "            Conv2d-4           [-1, 64, 16, 16]          36,864\n",
      "       BatchNorm2d-5           [-1, 64, 16, 16]             128\n",
      "            Conv2d-6           [-1, 64, 16, 16]          36,864\n",
      "       BatchNorm2d-7           [-1, 64, 16, 16]             128\n",
      "            Conv2d-8           [-1, 64, 16, 16]           4,096\n",
      "       BatchNorm2d-9           [-1, 64, 16, 16]             128\n",
      "             ReLU-10           [-1, 64, 16, 16]               0\n",
      "          Dropout-11           [-1, 64, 16, 16]               0\n",
      "    ResidualBlock-12           [-1, 64, 16, 16]               0\n",
      "           Conv2d-13            [-1, 128, 8, 8]          73,728\n",
      "      BatchNorm2d-14            [-1, 128, 8, 8]             256\n",
      "           Conv2d-15            [-1, 128, 8, 8]         147,456\n",
      "      BatchNorm2d-16            [-1, 128, 8, 8]             256\n",
      "           Conv2d-17            [-1, 128, 8, 8]           8,192\n",
      "      BatchNorm2d-18            [-1, 128, 8, 8]             256\n",
      "             ReLU-19            [-1, 128, 8, 8]               0\n",
      "          Dropout-20            [-1, 128, 8, 8]               0\n",
      "    ResidualBlock-21            [-1, 128, 8, 8]               0\n",
      "           Conv2d-22            [-1, 256, 4, 4]         294,912\n",
      "      BatchNorm2d-23            [-1, 256, 4, 4]             512\n",
      "           Conv2d-24            [-1, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-25            [-1, 256, 4, 4]             512\n",
      "           Conv2d-26            [-1, 256, 4, 4]          32,768\n",
      "      BatchNorm2d-27            [-1, 256, 4, 4]             512\n",
      "             ReLU-28            [-1, 256, 4, 4]               0\n",
      "          Dropout-29            [-1, 256, 4, 4]               0\n",
      "    ResidualBlock-30            [-1, 256, 4, 4]               0\n",
      "AdaptiveAvgPool2d-31            [-1, 256, 1, 1]               0\n",
      "          Dropout-32            [-1, 256, 1, 1]               0\n",
      "           Linear-33                   [-1, 10]           2,570\n",
      "================================================================\n",
      "Total params: 1,231,818\n",
      "Trainable params: 1,231,818\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 3.47\n",
      "Params size (MB): 4.70\n",
      "Estimated Total Size (MB): 8.18\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleResNet().to(device)\n",
    "summary(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4dc153e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T05:30:00.702538Z",
     "iopub.status.busy": "2025-03-09T05:30:00.702308Z",
     "iopub.status.idle": "2025-03-09T05:36:04.075099Z",
     "shell.execute_reply": "2025-03-09T05:36:04.073925Z"
    },
    "papermill": {
     "duration": 363.382026,
     "end_time": "2025-03-09T05:36:04.081090",
     "exception": false,
     "start_time": "2025-03-09T05:30:00.699064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training Loss: 1.366642882458318, Training Accuracy: 49.9875%, Validation Accuracy: 60.67%\n",
      "Epoch 2 - Training Loss: 0.9626219830573938, Training Accuracy: 65.7225%, Validation Accuracy: 62.46%\n",
      "Epoch 3 - Training Loss: 0.7899834574601902, Training Accuracy: 71.8275%, Validation Accuracy: 68.1%\n",
      "Epoch 4 - Training Loss: 0.6737822383737412, Training Accuracy: 76.225%, Validation Accuracy: 67.71%\n",
      "Epoch 5 - Training Loss: 0.591460543985184, Training Accuracy: 79.385%, Validation Accuracy: 75.0%\n",
      "Epoch 6 - Training Loss: 0.5144773446523343, Training Accuracy: 82.085%, Validation Accuracy: 78.35%\n",
      "Epoch 7 - Training Loss: 0.4572070062922213, Training Accuracy: 83.8025%, Validation Accuracy: 75.36%\n",
      "Epoch 8 - Training Loss: 0.4019606143902666, Training Accuracy: 85.7575%, Validation Accuracy: 79.37%\n",
      "Epoch 9 - Training Loss: 0.35915365448584574, Training Accuracy: 87.2825%, Validation Accuracy: 79.95%\n",
      "Epoch 10 - Training Loss: 0.315658349531908, Training Accuracy: 88.7075%, Validation Accuracy: 78.66%\n",
      "Epoch 11 - Training Loss: 0.27481133340837094, Training Accuracy: 90.215%, Validation Accuracy: 72.94%\n",
      "Epoch 12 - Training Loss: 0.24705718940915392, Training Accuracy: 91.1675%, Validation Accuracy: 79.57%\n",
      "Epoch 13 - Training Loss: 0.2150185298138914, Training Accuracy: 92.355%, Validation Accuracy: 79.89%\n",
      "Epoch 14 - Training Loss: 0.1899307031577197, Training Accuracy: 93.185%, Validation Accuracy: 82.47%\n",
      "Epoch 15 - Training Loss: 0.1739291532423359, Training Accuracy: 93.8325%, Validation Accuracy: 80.2%\n",
      "Epoch 16 - Training Loss: 0.1570470477945317, Training Accuracy: 94.33%, Validation Accuracy: 82.08%\n",
      "Epoch 17 - Training Loss: 0.1493799270699009, Training Accuracy: 94.7425%, Validation Accuracy: 82.45%\n",
      "Epoch 18 - Training Loss: 0.1331186117812658, Training Accuracy: 95.2475%, Validation Accuracy: 80.24%\n",
      "Epoch 19 - Training Loss: 0.11936689624652123, Training Accuracy: 95.78%, Validation Accuracy: 80.57%\n",
      "Epoch 20 - Training Loss: 0.11695881712788972, Training Accuracy: 95.7575%, Validation Accuracy: 80.8%\n",
      "Epoch 21 - Training Loss: 0.11483612920815191, Training Accuracy: 95.8725%, Validation Accuracy: 82.17%\n",
      "Epoch 22 - Training Loss: 0.09916792500514192, Training Accuracy: 96.495%, Validation Accuracy: 81.62%\n",
      "Epoch 23 - Training Loss: 0.09567554151050199, Training Accuracy: 96.635%, Validation Accuracy: 81.58%\n",
      "Epoch 24 - Training Loss: 0.0842054953245214, Training Accuracy: 97.0375%, Validation Accuracy: 82.48%\n",
      "Epoch 25 - Training Loss: 0.08534957151621961, Training Accuracy: 96.99%, Validation Accuracy: 82.15%\n",
      "Epoch 26 - Training Loss: 0.08841508432342031, Training Accuracy: 96.8875%, Validation Accuracy: 81.45%\n",
      "Epoch 27 - Training Loss: 0.07771818962888405, Training Accuracy: 97.3075%, Validation Accuracy: 80.24%\n",
      "Epoch 28 - Training Loss: 0.07669603338720984, Training Accuracy: 97.2925%, Validation Accuracy: 80.85%\n",
      "Epoch 29 - Training Loss: 0.07550191982521322, Training Accuracy: 97.3325%, Validation Accuracy: 81.7%\n",
      "Epoch 30 - Training Loss: 0.07881350391291486, Training Accuracy: 97.22%, Validation Accuracy: 81.69%\n",
      "Epoch 31 - Training Loss: 0.07161841208275896, Training Accuracy: 97.4925%, Validation Accuracy: 79.98%\n",
      "Epoch 32 - Training Loss: 0.06617346357185239, Training Accuracy: 97.775%, Validation Accuracy: 82.68%\n",
      "Epoch 33 - Training Loss: 0.06040892132614462, Training Accuracy: 97.84%, Validation Accuracy: 81.27%\n",
      "Epoch 34 - Training Loss: 0.06636613214941928, Training Accuracy: 97.7275%, Validation Accuracy: 83.06%\n",
      "Epoch 35 - Training Loss: 0.06252645382199425, Training Accuracy: 97.9425%, Validation Accuracy: 80.38%\n",
      "Epoch 36 - Training Loss: 0.058355043874309655, Training Accuracy: 98.015%, Validation Accuracy: 83.57%\n",
      "Epoch 37 - Training Loss: 0.058843443908106786, Training Accuracy: 97.9575%, Validation Accuracy: 82.87%\n",
      "Epoch 38 - Training Loss: 0.056907888497419346, Training Accuracy: 98.02%, Validation Accuracy: 82.71%\n",
      "Epoch 39 - Training Loss: 0.05608814052445963, Training Accuracy: 97.9675%, Validation Accuracy: 83.15%\n",
      "Epoch 40 - Training Loss: 0.05309760804844502, Training Accuracy: 98.165%, Validation Accuracy: 82.24%\n",
      "Epoch 41 - Training Loss: 0.050263129103298006, Training Accuracy: 98.22%, Validation Accuracy: 83.73%\n",
      "Epoch 42 - Training Loss: 0.05063435145930503, Training Accuracy: 98.19%, Validation Accuracy: 83.29%\n",
      "Epoch 43 - Training Loss: 0.054787472271309874, Training Accuracy: 98.095%, Validation Accuracy: 82.72%\n",
      "Epoch 44 - Training Loss: 0.052988539726589436, Training Accuracy: 98.1075%, Validation Accuracy: 83.54%\n",
      "Epoch 45 - Training Loss: 0.04712661914973737, Training Accuracy: 98.3825%, Validation Accuracy: 83.28%\n",
      "Epoch 46 - Training Loss: 0.04294117239449685, Training Accuracy: 98.525%, Validation Accuracy: 83.34%\n",
      "Epoch 47 - Training Loss: 0.04313799784408686, Training Accuracy: 98.4825%, Validation Accuracy: 83.22%\n",
      "Epoch 48 - Training Loss: 0.05249675775851352, Training Accuracy: 98.17%, Validation Accuracy: 83.02%\n",
      "Epoch 49 - Training Loss: 0.04879574539934318, Training Accuracy: 98.2775%, Validation Accuracy: 83.5%\n",
      "Epoch 50 - Training Loss: 0.04352321657843102, Training Accuracy: 98.505%, Validation Accuracy: 82.05%\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# DataLoaders for Training, Validation\n",
    "training_loader = DataLoader(training_data, batch_size=128, shuffle=True, num_workers=4)\n",
    "validation_loader = DataLoader(validation_data, batch_size=128, shuffle=False, num_workers=4)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total_train_predictions = 0\n",
    "    total_train_correct = 0\n",
    "\n",
    "    for images, labels in training_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predictions = torch.max(outputs, dim=1)\n",
    "        \n",
    "        num_predictions = labels.size(dim=0)\n",
    "        num_correct = (predictions == labels).sum().item()\n",
    "        \n",
    "        total_train_predictions += num_predictions\n",
    "        total_train_correct += num_correct\n",
    "\n",
    "    model.eval()\n",
    "    total_val_predictions = 0\n",
    "    total_val_correct = 0\n",
    "\n",
    "    for images, labels in validation_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "\n",
    "        _, predictions = torch.max(outputs, dim=1)\n",
    "\n",
    "        num_predictions = labels.size(dim=0)\n",
    "        num_correct = (predictions == labels).sum().item()\n",
    "\n",
    "        total_val_predictions += num_predictions\n",
    "        total_val_correct += num_correct\n",
    "\n",
    "    print('Epoch {} - Training Loss: {}, Training Accuracy: {}%, Validation Accuracy: {}%'.format(epoch+1, running_loss / len(training_loader), total_train_correct * 100 / total_train_predictions, total_val_correct * 100 / total_val_predictions))\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b621e1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T05:36:04.091995Z",
     "iopub.status.busy": "2025-03-09T05:36:04.091716Z",
     "iopub.status.idle": "2025-03-09T05:36:04.482743Z",
     "shell.execute_reply": "2025-03-09T05:36:04.481518Z"
    },
    "papermill": {
     "duration": 0.398089,
     "end_time": "2025-03-09T05:36:04.484181",
     "exception": false,
     "start_time": "2025-03-09T05:36:04.086092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n",
      "torch.Size([3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# Changing to Tensor and adjusting shape before test\n",
    "print(testing_data[0].shape)\n",
    "testing_data = [(transforms.ToTensor()(image)) for image in testing_data]\n",
    "print(testing_data[0].shape)\n",
    "# DataLoader\n",
    "testing_loader = DataLoader(testing_data, batch_size=128, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96a2508d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T05:36:04.502706Z",
     "iopub.status.busy": "2025-03-09T05:36:04.502264Z",
     "iopub.status.idle": "2025-03-09T05:36:05.246002Z",
     "shell.execute_reply": "2025-03-09T05:36:05.244962Z"
    },
    "papermill": {
     "duration": 0.753864,
     "end_time": "2025-03-09T05:36:05.247613",
     "exception": false,
     "start_time": "2025-03-09T05:36:04.493749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted! Check output for submission.csv\n"
     ]
    }
   ],
   "source": [
    "## Final output is file called submission.csv with columns ID, Labels\n",
    "\n",
    "model.eval()\n",
    "test_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images in testing_loader:\n",
    "        images = images.to(device) \n",
    "        outputs = model(images) \n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        \n",
    "        # for prediction in predictions:\n",
    "        #     test_predictions.append(prediction.item())\n",
    "        test_predictions.extend(predictions.cpu().numpy())\n",
    "\n",
    "test_predictions_dict = {'ID': np.arange(len(test_predictions)), 'Labels': test_predictions}\n",
    "test_predictions_df = pd.DataFrame(test_predictions_dict)\n",
    "test_predictions_df.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "print(\"Submitted! Check output for submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11145869,
     "sourceId": 93057,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 430.898353,
   "end_time": "2025-03-09T05:36:07.075413",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-09T05:28:56.177060",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
