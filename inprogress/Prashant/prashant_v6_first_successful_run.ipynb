{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae56a754",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-09T05:05:40.752621Z",
     "iopub.status.busy": "2025-03-09T05:05:40.752363Z",
     "iopub.status.idle": "2025-03-09T05:05:41.507010Z",
     "shell.execute_reply": "2025-03-09T05:05:41.506074Z"
    },
    "papermill": {
     "duration": 0.759693,
     "end_time": "2025-03-09T05:05:41.508455",
     "exception": false,
     "start_time": "2025-03-09T05:05:40.748762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar_test_nolabel.pkl\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/data_batch_1\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/data_batch_2\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/batches.meta\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/test_batch\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/data_batch_3\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/data_batch_5\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/data_batch_4\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/readme.html\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "151c2beb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T05:05:41.514796Z",
     "iopub.status.busy": "2025-03-09T05:05:41.514420Z",
     "iopub.status.idle": "2025-03-09T05:05:50.453678Z",
     "shell.execute_reply": "2025-03-09T05:05:50.452558Z"
    },
    "papermill": {
     "duration": 8.943875,
     "end_time": "2025-03-09T05:05:50.455181",
     "exception": false,
     "start_time": "2025-03-09T05:05:41.511306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'airplane', b'automobile', b'bird', b'cat', b'deer', b'dog', b'frog', b'horse', b'ship', b'truck']\n",
      "50000\n",
      "50000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "classes_dict = unpickle(\"/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/batches.meta\")\n",
    "label_names = classes_dict[b'label_names']\n",
    "print(label_names)\n",
    "\n",
    "# Load training data in batches, then combine\n",
    "training_data = []\n",
    "training_labels = []\n",
    "for i in range(1, 6):\n",
    "    training_fp = \"/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/data_batch_{}\".format(i)\n",
    "    batch = unpickle(training_fp)\n",
    "    batch_data = batch[b'data']\n",
    "    batch_labels = batch[b'labels']\n",
    "    for i in range(len(batch_data)):\n",
    "        training_data.append(batch_data[i])\n",
    "        training_labels.append(batch_labels[i])\n",
    "\n",
    "# Load test dataset\n",
    "testing_fp = '/kaggle/input/deep-learning-spring-2025-project-1/cifar_test_nolabel.pkl'\n",
    "testing_batch = unpickle(testing_fp)\n",
    "testing_data = testing_batch[b'data']\n",
    "\n",
    "print(len(training_data))\n",
    "print(len(training_labels))\n",
    "print(len(testing_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46181f24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T05:05:50.463541Z",
     "iopub.status.busy": "2025-03-09T05:05:50.463149Z",
     "iopub.status.idle": "2025-03-09T05:05:50.467823Z",
     "shell.execute_reply": "2025-03-09T05:05:50.467166Z"
    },
    "papermill": {
     "duration": 0.009432,
     "end_time": "2025-03-09T05:05:50.469083",
     "exception": false,
     "start_time": "2025-03-09T05:05:50.459651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_to_rgb_tensor(image):\n",
    "    rgb_image = np.zeros((32, 32, 3), dtype=np.uint8)\n",
    "    red_idx, green_idx, blue_idx = 0, 1024, 2048\n",
    "    for row in range(0, 32):\n",
    "        for col in range(0, 32):\n",
    "            rgb_image[row, col] = [image[red_idx], image[green_idx], image[blue_idx]]\n",
    "            red_idx += 1\n",
    "            green_idx += 1\n",
    "            blue_idx += 1\n",
    "\n",
    "    rgb_tensor = transforms.ToTensor()(rgb_image)\n",
    "    return rgb_tensor\n",
    "\n",
    "# Test on Random Image\n",
    "# rand_num = random.randint(0, 10000)\n",
    "# rand_image = data_batch_1[b'data'][rand_num]\n",
    "# rand_image_rgb = convert_to_rgb(rand_image)\n",
    "\n",
    "# rand_img_data = Image.fromarray(rand_image_rgb, 'RGB')\n",
    "# img_data.save('test.png')\n",
    "# label = data_batch_1[b'labels'][rand_num]\n",
    "# print('Expected Image: ', label, '-', label_names[label])\n",
    "\n",
    "# ADD VISUAL DISPLAY OF IMAGE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16728b63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T05:05:50.474670Z",
     "iopub.status.busy": "2025-03-09T05:05:50.474453Z",
     "iopub.status.idle": "2025-03-09T05:06:39.291771Z",
     "shell.execute_reply": "2025-03-09T05:06:39.291067Z"
    },
    "papermill": {
     "duration": 48.822063,
     "end_time": "2025-03-09T05:06:39.293633",
     "exception": false,
     "start_time": "2025-03-09T05:05:50.471570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_data = [convert_to_rgb_tensor(image) for image in training_data]\n",
    "# training_data = np.array(training_data)\n",
    "# training_labels = np.array(training_labels)\n",
    "training_data = [(image, label) for image, label in zip(training_data, training_labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2ac9246",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T05:06:39.300196Z",
     "iopub.status.busy": "2025-03-09T05:06:39.299917Z",
     "iopub.status.idle": "2025-03-09T05:06:39.315132Z",
     "shell.execute_reply": "2025-03-09T05:06:39.314300Z"
    },
    "papermill": {
     "duration": 0.019936,
     "end_time": "2025-03-09T05:06:39.316640",
     "exception": false,
     "start_time": "2025-03-09T05:06:39.296704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_count = int(0.8 * len(training_data))\n",
    "validation_count = int(0.2 * len(training_data))\n",
    "\n",
    "training_data, validation_data = random_split(training_data, [training_count, validation_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5777e58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T05:06:39.323497Z",
     "iopub.status.busy": "2025-03-09T05:06:39.323271Z",
     "iopub.status.idle": "2025-03-09T05:06:39.336556Z",
     "shell.execute_reply": "2025-03-09T05:06:39.335974Z"
    },
    "papermill": {
     "duration": 0.018008,
     "end_time": "2025-03-09T05:06:39.337771",
     "exception": false,
     "start_time": "2025-03-09T05:06:39.319763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "#Basic Residual Block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        #when in_channels != out_channels\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)  #residual connection\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        return out\n",
    "\n",
    "class SimpleResNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = ResidualBlock(64, 64, stride=2)\n",
    "        self.layer2 = ResidualBlock(64, 128, stride=2)\n",
    "        self.layer3 = ResidualBlock(128, 256, stride=2)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = self.dropout(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28125f5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T05:06:39.343321Z",
     "iopub.status.busy": "2025-03-09T05:06:39.343122Z",
     "iopub.status.idle": "2025-03-09T05:06:40.374000Z",
     "shell.execute_reply": "2025-03-09T05:06:40.372958Z"
    },
    "papermill": {
     "duration": 1.035246,
     "end_time": "2025-03-09T05:06:40.375491",
     "exception": false,
     "start_time": "2025-03-09T05:06:39.340245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "              ReLU-3           [-1, 64, 32, 32]               0\n",
      "            Conv2d-4           [-1, 64, 16, 16]          36,864\n",
      "       BatchNorm2d-5           [-1, 64, 16, 16]             128\n",
      "            Conv2d-6           [-1, 64, 16, 16]          36,864\n",
      "       BatchNorm2d-7           [-1, 64, 16, 16]             128\n",
      "            Conv2d-8           [-1, 64, 16, 16]           4,096\n",
      "       BatchNorm2d-9           [-1, 64, 16, 16]             128\n",
      "             ReLU-10           [-1, 64, 16, 16]               0\n",
      "          Dropout-11           [-1, 64, 16, 16]               0\n",
      "    ResidualBlock-12           [-1, 64, 16, 16]               0\n",
      "           Conv2d-13            [-1, 128, 8, 8]          73,728\n",
      "      BatchNorm2d-14            [-1, 128, 8, 8]             256\n",
      "           Conv2d-15            [-1, 128, 8, 8]         147,456\n",
      "      BatchNorm2d-16            [-1, 128, 8, 8]             256\n",
      "           Conv2d-17            [-1, 128, 8, 8]           8,192\n",
      "      BatchNorm2d-18            [-1, 128, 8, 8]             256\n",
      "             ReLU-19            [-1, 128, 8, 8]               0\n",
      "          Dropout-20            [-1, 128, 8, 8]               0\n",
      "    ResidualBlock-21            [-1, 128, 8, 8]               0\n",
      "           Conv2d-22            [-1, 256, 4, 4]         294,912\n",
      "      BatchNorm2d-23            [-1, 256, 4, 4]             512\n",
      "           Conv2d-24            [-1, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-25            [-1, 256, 4, 4]             512\n",
      "           Conv2d-26            [-1, 256, 4, 4]          32,768\n",
      "      BatchNorm2d-27            [-1, 256, 4, 4]             512\n",
      "             ReLU-28            [-1, 256, 4, 4]               0\n",
      "          Dropout-29            [-1, 256, 4, 4]               0\n",
      "    ResidualBlock-30            [-1, 256, 4, 4]               0\n",
      "AdaptiveAvgPool2d-31            [-1, 256, 1, 1]               0\n",
      "          Dropout-32            [-1, 256, 1, 1]               0\n",
      "           Linear-33                   [-1, 10]           2,570\n",
      "================================================================\n",
      "Total params: 1,231,818\n",
      "Trainable params: 1,231,818\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 3.47\n",
      "Params size (MB): 4.70\n",
      "Estimated Total Size (MB): 8.18\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleResNet().to(device)\n",
    "summary(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3364b28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T05:06:40.381899Z",
     "iopub.status.busy": "2025-03-09T05:06:40.381643Z",
     "iopub.status.idle": "2025-03-09T05:12:37.508470Z",
     "shell.execute_reply": "2025-03-09T05:12:37.507234Z"
    },
    "papermill": {
     "duration": 357.136516,
     "end_time": "2025-03-09T05:12:37.514880",
     "exception": false,
     "start_time": "2025-03-09T05:06:40.378364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training Loss: 1.3912846531730871, Training Accuracy: 48.685%, Validation Accuracy: 54.64%\n",
      "Epoch 2 - Training Loss: 0.9814936505339016, Training Accuracy: 64.9025%, Validation Accuracy: 66.75%\n",
      "Epoch 3 - Training Loss: 0.8218419043400798, Training Accuracy: 70.635%, Validation Accuracy: 65.86%\n",
      "Epoch 4 - Training Loss: 0.6969062557426123, Training Accuracy: 75.4475%, Validation Accuracy: 66.08%\n",
      "Epoch 5 - Training Loss: 0.6115700562541097, Training Accuracy: 78.345%, Validation Accuracy: 72.16%\n",
      "Epoch 6 - Training Loss: 0.5367594270850904, Training Accuracy: 81.0825%, Validation Accuracy: 75.53%\n",
      "Epoch 7 - Training Loss: 0.46723480813038615, Training Accuracy: 83.7475%, Validation Accuracy: 76.04%\n",
      "Epoch 8 - Training Loss: 0.4058223199158812, Training Accuracy: 85.7075%, Validation Accuracy: 77.81%\n",
      "Epoch 9 - Training Loss: 0.36581811408836623, Training Accuracy: 87.07%, Validation Accuracy: 72.87%\n",
      "Epoch 10 - Training Loss: 0.3215964737886819, Training Accuracy: 88.505%, Validation Accuracy: 75.55%\n",
      "Epoch 11 - Training Loss: 0.2799495258175146, Training Accuracy: 90.085%, Validation Accuracy: 80.31%\n",
      "Epoch 12 - Training Loss: 0.2462841893632572, Training Accuracy: 91.1475%, Validation Accuracy: 79.13%\n",
      "Epoch 13 - Training Loss: 0.22261374131940043, Training Accuracy: 92.0825%, Validation Accuracy: 78.31%\n",
      "Epoch 14 - Training Loss: 0.19601510886471873, Training Accuracy: 92.98%, Validation Accuracy: 80.23%\n",
      "Epoch 15 - Training Loss: 0.18016133264611706, Training Accuracy: 93.455%, Validation Accuracy: 77.74%\n",
      "Epoch 16 - Training Loss: 0.1595433391392612, Training Accuracy: 94.22%, Validation Accuracy: 79.34%\n",
      "Epoch 17 - Training Loss: 0.15070761380770717, Training Accuracy: 94.585%, Validation Accuracy: 79.05%\n",
      "Epoch 18 - Training Loss: 0.13024923331535662, Training Accuracy: 95.395%, Validation Accuracy: 80.52%\n",
      "Epoch 19 - Training Loss: 0.12022207954678292, Training Accuracy: 95.6775%, Validation Accuracy: 80.8%\n",
      "Epoch 20 - Training Loss: 0.11786428524758488, Training Accuracy: 95.9075%, Validation Accuracy: 79.86%\n",
      "Epoch 21 - Training Loss: 0.1167892727512902, Training Accuracy: 95.77%, Validation Accuracy: 80.45%\n",
      "Epoch 22 - Training Loss: 0.10204224471752636, Training Accuracy: 96.3825%, Validation Accuracy: 81.77%\n",
      "Epoch 23 - Training Loss: 0.09425368237371642, Training Accuracy: 96.715%, Validation Accuracy: 77.62%\n",
      "Epoch 24 - Training Loss: 0.09859311924622463, Training Accuracy: 96.545%, Validation Accuracy: 79.12%\n",
      "Epoch 25 - Training Loss: 0.09134364494095785, Training Accuracy: 96.7625%, Validation Accuracy: 78.99%\n",
      "Epoch 26 - Training Loss: 0.07844758380097322, Training Accuracy: 97.2725%, Validation Accuracy: 79.28%\n",
      "Epoch 27 - Training Loss: 0.0807834408058526, Training Accuracy: 97.075%, Validation Accuracy: 82.62%\n",
      "Epoch 28 - Training Loss: 0.07583854377222138, Training Accuracy: 97.33%, Validation Accuracy: 81.63%\n",
      "Epoch 29 - Training Loss: 0.07574740056388865, Training Accuracy: 97.32%, Validation Accuracy: 80.3%\n",
      "Epoch 30 - Training Loss: 0.07657752485392383, Training Accuracy: 97.28%, Validation Accuracy: 80.77%\n",
      "Epoch 31 - Training Loss: 0.07081857305198622, Training Accuracy: 97.4625%, Validation Accuracy: 81.43%\n",
      "Epoch 32 - Training Loss: 0.07245919385407203, Training Accuracy: 97.425%, Validation Accuracy: 81.6%\n",
      "Epoch 33 - Training Loss: 0.06105804170954961, Training Accuracy: 97.865%, Validation Accuracy: 82.1%\n",
      "Epoch 34 - Training Loss: 0.0612097052000344, Training Accuracy: 97.825%, Validation Accuracy: 81.91%\n",
      "Epoch 35 - Training Loss: 0.06819961834163331, Training Accuracy: 97.61%, Validation Accuracy: 81.67%\n",
      "Epoch 36 - Training Loss: 0.05915787506598634, Training Accuracy: 97.9375%, Validation Accuracy: 82.49%\n",
      "Epoch 37 - Training Loss: 0.053013019656506594, Training Accuracy: 98.155%, Validation Accuracy: 82.68%\n",
      "Epoch 38 - Training Loss: 0.05443260037063505, Training Accuracy: 98.06%, Validation Accuracy: 81.66%\n",
      "Epoch 39 - Training Loss: 0.06066800147806779, Training Accuracy: 97.79%, Validation Accuracy: 82.44%\n",
      "Epoch 40 - Training Loss: 0.0558400453118899, Training Accuracy: 97.955%, Validation Accuracy: 81.64%\n",
      "Epoch 41 - Training Loss: 0.049371960629432346, Training Accuracy: 98.31%, Validation Accuracy: 82.88%\n",
      "Epoch 42 - Training Loss: 0.05503500727549814, Training Accuracy: 98.0375%, Validation Accuracy: 82.65%\n",
      "Epoch 43 - Training Loss: 0.054002558816962254, Training Accuracy: 98.19%, Validation Accuracy: 82.25%\n",
      "Epoch 44 - Training Loss: 0.053947138774116485, Training Accuracy: 98.155%, Validation Accuracy: 81.75%\n",
      "Epoch 45 - Training Loss: 0.04826707468656734, Training Accuracy: 98.265%, Validation Accuracy: 83.42%\n",
      "Epoch 46 - Training Loss: 0.04398318082867815, Training Accuracy: 98.44%, Validation Accuracy: 82.65%\n",
      "Epoch 47 - Training Loss: 0.048407730229865435, Training Accuracy: 98.3225%, Validation Accuracy: 82.54%\n",
      "Epoch 48 - Training Loss: 0.04741185866504574, Training Accuracy: 98.31%, Validation Accuracy: 83.24%\n",
      "Epoch 49 - Training Loss: 0.04333939015294035, Training Accuracy: 98.5075%, Validation Accuracy: 82.58%\n",
      "Epoch 50 - Training Loss: 0.04486470625917323, Training Accuracy: 98.3825%, Validation Accuracy: 82.5%\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# DataLoaders for Training, Validation\n",
    "training_loader = DataLoader(training_data, batch_size=128, shuffle=True, num_workers=4)\n",
    "validation_loader = DataLoader(validation_data, batch_size=128, shuffle=False, num_workers=4)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total_train_predictions = 0\n",
    "    total_train_correct = 0\n",
    "\n",
    "    for images, labels in training_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predictions = torch.max(outputs, dim=1)\n",
    "        \n",
    "        num_predictions = labels.size(dim=0)\n",
    "        num_correct = (predictions == labels).sum().item()\n",
    "        \n",
    "        total_train_predictions += num_predictions\n",
    "        total_train_correct += num_correct\n",
    "\n",
    "    model.eval()\n",
    "    total_val_predictions = 0\n",
    "    total_val_correct = 0\n",
    "\n",
    "    for images, labels in validation_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "\n",
    "        _, predictions = torch.max(outputs, dim=1)\n",
    "\n",
    "        num_predictions = labels.size(dim=0)\n",
    "        num_correct = (predictions == labels).sum().item()\n",
    "\n",
    "        total_val_predictions += num_predictions\n",
    "        total_val_correct += num_correct\n",
    "\n",
    "    print('Epoch {} - Training Loss: {}, Training Accuracy: {}%, Validation Accuracy: {}%'.format(epoch+1, running_loss / len(training_loader), total_train_correct * 100 / total_train_predictions, total_val_correct * 100 / total_val_predictions))\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da347ea0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T05:12:37.526289Z",
     "iopub.status.busy": "2025-03-09T05:12:37.525984Z",
     "iopub.status.idle": "2025-03-09T05:12:37.921811Z",
     "shell.execute_reply": "2025-03-09T05:12:37.920793Z"
    },
    "papermill": {
     "duration": 0.403218,
     "end_time": "2025-03-09T05:12:37.923232",
     "exception": false,
     "start_time": "2025-03-09T05:12:37.520014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n",
      "torch.Size([3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# Changing to Tensor and adjusting shape before test\n",
    "print(testing_data[0].shape)\n",
    "testing_data = [(transforms.ToTensor()(image)) for image in testing_data]\n",
    "print(testing_data[0].shape)\n",
    "# DataLoader\n",
    "testing_loader = DataLoader(testing_data, batch_size=128, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8eb6ac0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T05:12:37.934183Z",
     "iopub.status.busy": "2025-03-09T05:12:37.933909Z",
     "iopub.status.idle": "2025-03-09T05:12:38.669455Z",
     "shell.execute_reply": "2025-03-09T05:12:38.668434Z"
    },
    "papermill": {
     "duration": 0.742501,
     "end_time": "2025-03-09T05:12:38.670923",
     "exception": false,
     "start_time": "2025-03-09T05:12:37.928422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted! Check output for submission.csv\n"
     ]
    }
   ],
   "source": [
    "## Final output is file called submission.csv with columns ID, Labels\n",
    "\n",
    "model.eval()\n",
    "test_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images in testing_loader:\n",
    "        images = images.to(device) \n",
    "        outputs = model(images) \n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        \n",
    "        for prediction in predictions:\n",
    "            test_predictions.append(prediction.item())\n",
    "\n",
    "predictions_dict = {'ID': np.arange(len(test_predictions)), 'Labels': test_predictions}\n",
    "predictions_df = pd.DataFrame(predictions_dict)\n",
    "predictions_df.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "print(\"Submitted! Check output for submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11145869,
     "sourceId": 93057,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 422.487137,
   "end_time": "2025-03-09T05:12:40.599269",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-09T05:05:38.112132",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
